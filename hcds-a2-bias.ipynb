{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bias in Data\n",
    "### Kenten Danas\n",
    "#### An exploration of bias in data on Wikipedia, originally completed for University of Washington's DATA 512 class in Autumn 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to explore bias in data by looking at English Wikipedia pages on politicians from a variety of countries. I combine the article data with data on the countries' populations and a prediction of the quality of the article garnered from ORES (more information on this below), and explore whether these have an impact on the number of articles on politicians overall and the number of higher quality articles.\n",
    "\n",
    "This notebook is used to process the downloaded data, get article quality prediction data from ORES, munge the data from the different sources, and complete an analysis of the combined data. A discussion of the results can be found in the ReadMe of this repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary packages and initialize desired notebook settings\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_inateractivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two sources of data were used for this analysis; both are described in separate sections below. For both the data is publically available and easily downloaded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Article Data\n",
    "\n",
    "The first data set contains data about English Wikipedia articles on politicians, by country. It can be found at this link: \n",
    "\n",
    "https://figshare.com/articles/Untitled_Item/5513449\n",
    "\n",
    "This data is released under the CC-BY-SA 4.0 license, and so can be included here in this repo. \n",
    "\n",
    "From this page you can download a zip file containing the data, as well as R code used to generate the data. For the purpose of this analysis, only the page_data.csv is needed, so I have extracted that from the download and included it in the 'raw_data' folder of this repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page</th>\n",
       "      <th>country</th>\n",
       "      <th>rev_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Template:ZambiaProvincialMinisters</td>\n",
       "      <td>Zambia</td>\n",
       "      <td>235107991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bir I of Kanem</td>\n",
       "      <td>Chad</td>\n",
       "      <td>355319463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Template:Zimbabwe-politician-stub</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>391862046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Template:Uganda-politician-stub</td>\n",
       "      <td>Uganda</td>\n",
       "      <td>391862070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Template:Namibia-politician-stub</td>\n",
       "      <td>Namibia</td>\n",
       "      <td>391862409</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 page   country     rev_id\n",
       "0  Template:ZambiaProvincialMinisters    Zambia  235107991\n",
       "1                      Bir I of Kanem      Chad  355319463\n",
       "2   Template:Zimbabwe-politician-stub  Zimbabwe  391862046\n",
       "3     Template:Uganda-politician-stub    Uganda  391862070\n",
       "4    Template:Namibia-politician-stub   Namibia  391862409"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read page data csv from local data and look at first couple of rows\n",
    "pages = pd.read_csv('data_raw/page_data.csv')\n",
    "pages.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consistent with what is described on the figshare page for this data, page_data.csv contains the following columns:\n",
    "\n",
    " - page: the name of the English Wikipedia page (not cleaned)\n",
    " - country: the name of the country the politician was from\n",
    " - rev_id: the id of the last revision made to the page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Population Data\n",
    "\n",
    "The second data set used for this analysis contains world population by country, in millions of people, as of 2018. The data set can be found here: \n",
    "\n",
    "https://www.dropbox.com/s/5u7sy1xt7g0oi2c/WPDS_2018_data.csv?dl=0\n",
    "\n",
    "The origin of this data is from the Population Reference Bureau; more information on the data can be found on their website, here: https://www.prb.org/2018-world-population-data-sheet-with-focus-on-changing-age-structures/\n",
    "\n",
    "Since this data is not licensed, I have not included it in this repository. The code below loads the data locally. If you want to replicate this analysis, you can download the data from the link above and update the filepath used to read in the csv in the code below.\n",
    "\n",
    "Note that here I also do some minor data processing to make the analysis below easier, namely renaming the columns and converting the population to the full value rather than millions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>Population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFRICA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>42700000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Egypt</td>\n",
       "      <td>97000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Libya</td>\n",
       "      <td>6500000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Morocco</td>\n",
       "      <td>35200000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   country  Population\n",
       "0   AFRICA         NaN\n",
       "1  Algeria  42700000.0\n",
       "2    Egypt  97000000.0\n",
       "3    Libya   6500000.0\n",
       "4  Morocco  35200000.0"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read population data from local csv and review first couple of rows\n",
    "pop = pd.read_csv('C:/Users/kentd/OneDrive/Documents/School-Grad/DATA_512/WPDS_2018_data.csv')\n",
    "\n",
    "#Rename columns to make future analysis easier\n",
    "pop.rename(columns={'Geography': 'country', 'Population mid-2018 (millions)': 'Population'}, inplace=True)\n",
    "\n",
    "#Convert population to int, and then to raw value\n",
    "pop['Population'] = pd.to_numeric(pop['Population'], errors='coerce')\n",
    "pop['Population'] = pop['Population'] * 1e6\n",
    "pop.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Article Quality Predictions Using ORES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this analysis, I get the prediction of article quality from ORES, an API for machine learning developed by Wikimedia. See the following link for more information:\n",
    "\n",
    "https://www.mediawiki.org/wiki/ORES\n",
    "\n",
    "ORES takes a Wikipedia article ID and assigns a probability that the quality of the article falls into one of six categories. The highest probability is the category assigned to the article. The categories are (from best to worst quality):\n",
    "\n",
    " - FA - Featured article\n",
    " - GA - Good article\n",
    " - B - B-class article\n",
    " - C - C-class article\n",
    " - Start - Start-class article\n",
    " - Stub - Stub-class article\n",
    " \n",
    "For this analysis, I consider articles classified as 'FA' and 'GA' to be \"high quality\" articles.\n",
    "\n",
    "To get the predictions, I feed the pages dataset to the ORES system using the code below. Since the API documentation recommends batching 50 revision IDs per request, I have split the data into chunks of 50 rather than sending the entire dataframe. The function 'ores' I used to make the API requests is based on the example provided here: https://github.com/Ironholds/data-512-a2/blob/master/hcds-a2-bias_demo.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start with some housekeeping - define headers & API endpoint\n",
    "headers = {'User-Agent' : 'https://github.com/kentdanas', 'From' : 'kdanas@uw.edu'}\n",
    "endpoint = 'https://ores.wikimedia.org/v3/scores/{project}/?models={model}&revids={revids}'\n",
    "\n",
    "#Now define function to make the API call for a given list of revision ids\n",
    "def ores(rev_ids, headers=headers, endpoint=endpoint):\n",
    "    params = {'project' : 'enwiki',\n",
    "              'model'   : 'wp10',\n",
    "              'revids'  : '|'.join(str(x) for x in rev_ids)\n",
    "              }\n",
    "    api_call = requests.get(endpoint.format(**params))\n",
    "    response = api_call.json()\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the ORES function above to get predictions for each article by looping through 50 articles at a time. \n",
    "# Note, this chunk will take a few minutes to run; this is a good time to grab a cup of coffee!\n",
    "\n",
    "#Define start indexes\n",
    "index_start = 0\n",
    "index_stop = 49\n",
    "\n",
    "#Create empty dataframe to store results\n",
    "page_quality = pd.DataFrame(columns=('rev_id', 'article_quality'))\n",
    "\n",
    "while index_start < len(pages):\n",
    "    #Pull chunk of revision ids\n",
    "    rev_ids = list(pages['rev_id'][index_start:index_stop])\n",
    "\n",
    "    #Feed revision ids to ORES and get predictions\n",
    "    response = ores(rev_ids)\n",
    "\n",
    "    #pull out prediction for each rev_id from resulting json dump. Note that if the article was not found by ORES \n",
    "    # it will not have a prediction, hence the try/except statement. For articles with no prediction I filled the\n",
    "    # results with 'nan'\n",
    "    for rev_id in rev_ids:\n",
    "        rev_id = str(rev_id)\n",
    "        \n",
    "        try:\n",
    "            prediction = response['enwiki']['scores'][rev_id]['wp10']['score']['prediction']\n",
    "\n",
    "        except:\n",
    "            prediction = np.nan\n",
    "\n",
    "        #append results to dataframe\n",
    "        page_quality = page_quality.append({'rev_id':rev_id, 'article_quality':prediction}, ignore_index=True) \n",
    "\n",
    "    #Redefine indexes\n",
    "    index_start += 50\n",
    "    index_stop = min(index_stop+50, len(pages))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Datasets\n",
    "\n",
    "Now that I have the article quality prediction data from ORES, I combine the three data sets into one so they can be used for the analysis. The final dataframe has the following columns:\n",
    "\n",
    " - article_name: the (uncleaned) article name\n",
    " - country: the country of the politician in the article\n",
    " - revision_id: the id of the last revision of the article\n",
    " - article_quality: the ORES prediction of the article quality\n",
    " - population: the population of the country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_name</th>\n",
       "      <th>country</th>\n",
       "      <th>revision_id</th>\n",
       "      <th>article_quality</th>\n",
       "      <th>Population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Template:ZambiaProvincialMinisters</td>\n",
       "      <td>Zambia</td>\n",
       "      <td>235107991</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17700000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gladys Lundwe</td>\n",
       "      <td>Zambia</td>\n",
       "      <td>757566606</td>\n",
       "      <td>Stub</td>\n",
       "      <td>17700000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mwamba Luchembe</td>\n",
       "      <td>Zambia</td>\n",
       "      <td>764848643</td>\n",
       "      <td>Stub</td>\n",
       "      <td>17700000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thandiwe Banda</td>\n",
       "      <td>Zambia</td>\n",
       "      <td>768166426</td>\n",
       "      <td>Start</td>\n",
       "      <td>17700000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sylvester Chisembele</td>\n",
       "      <td>Zambia</td>\n",
       "      <td>776082926</td>\n",
       "      <td>C</td>\n",
       "      <td>17700000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         article_name country  revision_id article_quality  \\\n",
       "0  Template:ZambiaProvincialMinisters  Zambia    235107991             NaN   \n",
       "1                       Gladys Lundwe  Zambia    757566606            Stub   \n",
       "2                     Mwamba Luchembe  Zambia    764848643            Stub   \n",
       "3                      Thandiwe Banda  Zambia    768166426           Start   \n",
       "4                Sylvester Chisembele  Zambia    776082926               C   \n",
       "\n",
       "   Population  \n",
       "0  17700000.0  \n",
       "1  17700000.0  \n",
       "2  17700000.0  \n",
       "3  17700000.0  \n",
       "4  17700000.0  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#First combine the ORES predictions and the page data (note that I need to convert the rev_id type to an int first)\n",
    "page_quality['rev_id'] = pd.to_numeric(page_quality['rev_id'], errors='coerce')\n",
    "final_dataset = pages.merge(page_quality, how='left', on=['rev_id'])\n",
    "\n",
    "#Next, merge with population data. This is done as an inner join since I only want to keep articles for which \n",
    "#there is a population, and I don't need the population for any countries without any articles\n",
    "final_dataset = final_dataset.merge(pop, how='inner', on=['country'])\n",
    "\n",
    "#Rename a couple of columns\n",
    "final_dataset.rename(columns={'page': 'article_name', 'rev_id': 'revision_id'}, inplace=True)\n",
    "\n",
    "#Save to CSV\n",
    "final_dataset.to_csv('data_clean/final_article_dataset.csv', index = False)\n",
    "\n",
    "#Take a look at the resulting dataframe\n",
    "final_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "The analysis on this data set consists of a calculation of the proportion of articles per population for each country, and proportion of high quality articles for each country. A detailed discussion of the results of this analysis can be found in the ReadMe of this repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
